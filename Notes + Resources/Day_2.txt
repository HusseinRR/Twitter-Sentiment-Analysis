Objectives: 
Research the internet for potential interesting models and how to train them properly
Try some code...
Learn the difference between structured and unstructured text data
Shift your focus to sentimental analysis

Site for purchasing data esg oriented: (price around 250 dollars) id we decide to fine-tune
https://datarade.ai/data-categories/esg-sentiment-data


An intern describes his work experience at parabole.ai where he developed ESG-BERT by
further pre-training Google’s “BERT” language model on large unstructured Sustainability text corpora.
https://towardsdatascience.com/nlp-meets-sustainable-investing-d0542b3c264b
Very interesting approach, there's a need to understand some key concepts the intern used in his work
Worth testing
https://github.com/mukut03/ESG-BERT
Idea to be discussed with Alexander: 
Three steps algorithm: (reliable or non-reliable news) -> (Categorize into a certain label) -> (sentiment analysis + or -)
Original BERT model:
https://github.com/google-research/bert : This is implemented in TensorFlow however
There are equivalents on HuggingFace


6 pretrained models for text classification:
https://www.analyticsvidhya.com/blog/2020/03/6-pretrained-models-text-classification/

How to deal with many laguages:
Relying on translation motors could be a possibility

Another interesting model to classify data into one of the three categories(E,S or G):
https://huggingface.co/yiyanghkust/finbert-esg

\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\

Focusing on sentimental analysis:

Another plateform to dig potential models: to be seen later
https://fasttext.cc/

LSTM concept to explore:
Have a look at https://au.mathworks.com/help/textanalytics/ug/classify-text-data-using-deep-learning.html 
and https://au.mathworks.com/help/deeplearning/ug/multilabel-text-classification-using-deep-learning.html
and https://www.kaggle.com/code/arunmohan003/sentiment-analysis-using-lstm-pytorch (in PyTorch)

Key conclusion for the moment: if it comes to finetuning a pre-trained model, it will be either Bert or XLNet

For Bert: i added a pdf in the resources, it was read diagnally, to be read calmly in the morning...

Could be interesting for twitter:
https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest (three labels in output)
Not ideal, could be finetuned but i guess there are more interesting models

Vader model: 
(not ideal since it can't be finetuned easily, no direct implementation on HuggingFace)
https://towardsdatascience.com/the-most-favorable-pre-trained-sentiment-classifiers-in-python-9107c06442c6

DistilBERT base uncased finetuned SST-2:
https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english?text=The+carbon+emissions+at+Apple+increased+by+10%25
Binary classificator, not bad but not too specific for ESG:
For example ït labelized "The carbon emissions at Apple increased by 10%" as a positive thing
Idea to try: changing the last layer and trainig the model on each of the three segments (E, S or G)
This link explains how to finetune distilbert: (very complete approach covering almost all the aspects we'll eventually tackle on)
https://medium.com/nlplanet/fine-tuning-distilbert-on-senator-tweets-a6f2425ca50e
I conclude it's an interesting choice for our work, definitely worth discussing with Alexander.
One pattern i noticed in the finetuning process is that we always train the model as a whole without freezing any layers.

Youtube Playlist on BERT usage to be seen ASAP:
https://www.youtube.com/watch?v=-CAC4wK9Ey0&list=PLEJK-H61XlwxpfpVzt3oDLQ8vr1XiEhev
https://github.com/curiousily  the git account

https://www.kaggle.com/code/chayan8/sentiment-analysis-using-bert-pytorch/notebook#Sentiment-Analysis-with-Deep-Learning-using-BERT
This notebook is quite useful to make a sentiment analyser from Bert, the only downside is the need for a dataset to train on

A possibility would be to train the model on an unsupervised scrapped data set...?


Scrap the tweets
Test sentimental analysis
The relation between a firm and the tweet

Prepare an overview for everything you've done this week till monday ;)