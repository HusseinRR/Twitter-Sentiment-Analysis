Objectives: 
Research the internet for potential interesting models and how to train them properly
Try some code...
Learn the difference between structured and unstructured text data
Shift your focus to sentimental analysis

Site for purchasing data esg oriented: (price around 250 dollars) id we decide to fine-tune
https://datarade.ai/data-categories/esg-sentiment-data


An intern describes his work experience at parabole.ai where he developed ESG-BERT by
further pre-training Google’s “BERT” language model on large unstructured Sustainability text corpora.
https://towardsdatascience.com/nlp-meets-sustainable-investing-d0542b3c264b
Very interesting approach, there's a need to understand some key concepts the intern used in his work
Worth testing
https://github.com/mukut03/ESG-BERT
Idea to be discussed with Alexander: 
Three steps algorithm: (reliable or non-reliable news) -> (Categorize into a certain label) -> (sentiment analysis + or -)
Original BERT model:
https://github.com/google-research/bert : This is implemented in TensorFlow however
There are equivalents on HuggingFace


6 pretrained models for text classification:
https://www.analyticsvidhya.com/blog/2020/03/6-pretrained-models-text-classification/

How to deal with many laguages:
Relying on translation motors could be a possibility

Another interesting model to classify data into one of the three categories(E,S or G):
https://huggingface.co/yiyanghkust/finbert-esg

\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\

Focusing on sentimental analysis:

Another plateform to dig potential models: to be seen later
https://fasttext.cc/

Have a look at https://au.mathworks.com/help/textanalytics/ug/classify-text-data-using-deep-learning.html 
and https://au.mathworks.com/help/deeplearning/ug/multilabel-text-classification-using-deep-learning.html

Key conclusion for the moment: if it comes to finetuning a pre-trained model, it will be either Bert or XLNet

Could be interesting for twitter:
https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest (three labels in output)

Vader model: (not ideal since it can't be finetuned easily, no direct implementation on Kaggle)
https://towardsdatascience.com/the-most-favorable-pre-trained-sentiment-classifiers-in-python-9107c06442c6

Youtube Playlist on BERT usage to be seen ASAP:
https://www.youtube.com/watch?v=-CAC4wK9Ey0&list=PLEJK-H61XlwxpfpVzt3oDLQ8vr1XiEhev
https://github.com/curiousily  the git account


