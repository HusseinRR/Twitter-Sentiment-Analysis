{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import pipeline\n",
    "import tweepy as tw\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key= 'dDhUnEB64ZYErOZzZ8fikHU9K'\n",
    "consumer_secret= 'MFTTcO4DyqsvaXwS2i7SXLu3UMRHUeLNKYZ8MhF4yO9IQ2Io41'\n",
    "access_token= '1231580456572854273-OlByhW9omNeGMXcnOWOwbDLDnVkh0W'\n",
    "access_token_secret='v7Mqon3TUNbQXo1Cja76PYs5Yk3LvByJc1Lz43FQRYS62'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe(text, size = 100, lang = \"en\"):\n",
    "    tweets = tw.Cursor(api.search ,q= text, lang=lang , tweet_mode=\"extended\").items(size)\n",
    "    tweet =[]\n",
    "    for i in tweets :\n",
    "        tweet.append(i.full_text)\n",
    "    df = pd.DataFrame({'tweet': tweet})\n",
    "    #Removing retweets:\n",
    "    df = df[~df.tweet.str.contains(\"RT\")] \n",
    "    df= df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FinBERT used to filter the ESG tweets\n",
    "\n",
    "finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-esg',num_labels=4)\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-esg')\n",
    "esg_filter = pipeline(\"text-classification\", model=finbert, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# RoBERTa used for sentiment analysis\n",
    "\n",
    "ROBERTA = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer_sent = AutoTokenizer.from_pretrained(ROBERTA)\n",
    "config_sent = AutoConfig.from_pretrained(ROBERTA)\n",
    "# PT\n",
    "model_sent = RobertaForSequenceClassification.from_pretrained(ROBERTA)\n",
    "\n",
    "sentiment = pipeline(\"sentiment-analysis\", model=model_sent, tokenizer=tokenizer_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model(text, preprocess, esg_filter, sentiment):\n",
    "    text = preprocess(text)\n",
    "    if esg_filter(text)[0]['label'] == 'None':\n",
    "        return 0\n",
    "    else:\n",
    "        if sentiment(text)[0]['label'] == 'Neutral':\n",
    "            return 0\n",
    "        if sentiment(text)[0]['label'] == 'Positive':\n",
    "            return sentiment(text)[0]['score']\n",
    "        if sentiment(text)[0]['label'] == 'Negative':\n",
    "            return (-1)* sentiment(text)[0]['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5015495419502258\n",
      "0\n",
      "-0.9027664661407471\n",
      "0.8792818188667297\n",
      "0.814257025718689\n",
      "0.896986722946167\n",
      "-0.7128043174743652\n"
     ]
    }
   ],
   "source": [
    "#Some sample testing\n",
    "\n",
    "text0 = \"The carbon consumption at Apple has been increasing at a fast pace.\"\n",
    "print(simple_model(text0, preprocess, esg_filter, sentiment))\n",
    "\n",
    "text1 = \"I summarized McKinsey's 10 sources of competitive advantage in one image and included some examples that I think fit the description (list is not exhaustive, of course)\"\n",
    "print(simple_model(text1, preprocess, esg_filter, sentiment))\n",
    "\n",
    "text2 = \"Most companies suck at solving problems. So they pay McKinsey $500K+ to do it for them\"\n",
    "print(simple_model(text2, preprocess, esg_filter, sentiment))\n",
    "\n",
    "text3 = \"We’re here to provide tips, tricks and helpful information when you need it most. We’re available every day to answer your questions, from 5am-8pm Pacific.\"\n",
    "print(simple_model(text3, preprocess, esg_filter, sentiment))\n",
    "\n",
    "text4 = \"I think it’s so cool that Apple is trying to reduce carbon emission by leaving certain things that most people don’t use out of the box but I can already hear the customers yelling at me about it\"\n",
    "print(simple_model(text4, preprocess, esg_filter, sentiment))\n",
    "\n",
    "text5 = \"HAHAHA honestly I’ve been an Apple user for years, since the 3GS actually!  but after Samsung released this ad ima go out and get me one.Reduces carbon emission my butt Apple\"\n",
    "print(simple_model(text5, preprocess, esg_filter, sentiment))\n",
    "\n",
    "text6 = \"I worry that apple is increasing its average wage even though this will reduce inequalities\"\n",
    "print(simple_model(text6, preprocess, esg_filter, sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ESG(df, preprocess, esg_filter, sentiment):\n",
    "    ESG_score = 0\n",
    "    k = 0\n",
    "    for i in range(df['tweet'].shape[0]):\n",
    "        a = simple_model(df['tweet'][i], preprocess, esg_filter, sentiment)\n",
    "        if a != 0:\n",
    "            k+=1\n",
    "        ESG_score += a\n",
    "\n",
    "    ESG_score = ESG_score/k\n",
    "    return ESG_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3147019426027934"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tesla:\n",
    "\n",
    "df = dataframe(\"#tesla\")\n",
    "ESG(df, preprocess, esg_filter, sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6853737950325012"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exxon:\n",
    "\n",
    "df = dataframe(\"#exxon\")\n",
    "ESG(df, preprocess, esg_filter, sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5603437469555781"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Microsoft:\n",
    "\n",
    "df = dataframe(\"#Microsoft\")\n",
    "ESG(df, preprocess, esg_filter, sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6623695632990669"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accenture:\n",
    "\n",
    "df = dataframe(\"#Accenture\")\n",
    "ESG(df, preprocess, esg_filter, sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.33278047541777295"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fox:\n",
    "\n",
    "df = dataframe(\"#Fox\")\n",
    "ESG(df, preprocess, esg_filter, sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2602367627620697"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tencent:\n",
    "\n",
    "df = dataframe(\"#Tencent\", 1000)\n",
    "ESG(df, preprocess, esg_filter, sentiment)\n",
    "\n",
    "#with size = 100 it gave 0.88\n",
    "#This makes a bit more sense ~"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
